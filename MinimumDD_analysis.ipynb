{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf7480-8878-486f-867a-152c888b4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f863ffd-9b4f-45d3-a748-68f6ccf6ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (replace with your actual data and feature names)\n",
    "data=pd.read_csv(\"C:\\\\Users\\\\HP\\\\Desktop\\\\final_MDD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae12ff0-0773-4d0e-b93f-a24378cea042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfb768-0207-4d81-968e-e1d54de3d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78193e-e712-45b9-86c5-9b2e4fe848c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510851f-4865-40c7-b082-825d44acaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021d8f3-a7f2-4ef1-b716-35fdc1a1ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372cb8d-fb6b-4011-973e-627d39e8b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation using KNN imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_df = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a3abe-a9cc-447f-834f-67bd93381f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = imputed_df.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf47c1-1573-4a77-a9a1-ddc1b368e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(imputed_df.corr(), annot=True,fmt=\".2f\") # if annot set to False, the correlation values are not shown in the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d4eca-e5c7-4a2c-a0a3-5c4e4bf39d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputed_df.drop('target', axis=1)  # Features\n",
    "y = imputed_df['target']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3cb46c-a18e-4328-8278-d10226ea45fd",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3499310-d205-4f1d-8d82-7c52cea21f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "vt = VarianceThreshold(threshold=0.1)\n",
    "X_vt = vt.fit_transform(X)\n",
    "vt_variances = vt.variances_\n",
    "vt_selected_features = [X.columns[i] for i in range(X.shape[1]) if vt.get_support()[i]]\n",
    "print(f\"Variance Threshold selected {len(vt_selected_features)} features: {vt_selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cdd011-f05e-4be7-8bfa-15403185bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_vt_train, X_vt_test, y_vt_train, y_vt_test = train_test_split(X_vt, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afa6c2-c81d-4573-826b-ecc993005088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "model_vt = RandomForestClassifier(random_state=42)\n",
    "model_vt.fit(X_vt_train, y_vt_train)\n",
    "f1_vt = f1_score(y_vt_test, model_vt.predict(X_vt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c740e2-b97a-4beb-97c6-cd492a90fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 score for Variance Threshold: {f1_vt:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ef0e3-4296-4c4d-8fe6-ea4948abf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected features based on their variances\n",
    "selected_features = X.columns[vt.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77262f6-63d6-45b2-a59b-97a31d529348",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d75a54-f077-4a63-a5ae-fd2ebd190af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f2f3b-a17a-42f1-ad84-b6ec9e057ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual data and feature names)\n",
    "selected_features = ['age_of_child', 'child_sex', 'birth_order', 'current_breast_feeding', 'birth_weight', 'birth_interval', 'womens_age', 'Place_of_residence', 'mother_edu_stat', 'marital_stats', 'no_of_under_five_child', 'media_exposure', 'sex_of_hh_head', 'household_size', 'household_wealth_stat', 'water_source', 'ANc_visit', 'place_of_delivery']\n",
    "variances = np.random.rand(len(selected_features))  # Random variances for demonstration\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(selected_features, variances, color='skyblue')\n",
    "plt.xlabel('Selected Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Variance of Selected Features')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41b223-baf1-42c4-a2de-7e006a76db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Concatenate y (target variable) and selected features into a new DataFrame\n",
    "new_df = pd.concat([imputed_df[selected_features], imputed_df['target']], axis=1)\n",
    "\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5fa6f-aa7e-4dd1-8741-39531e3944d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf87d2-4334-4ba7-8e26-03e1aeb46415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop('target', axis=1)  # Features\n",
    "Y = new_df['target']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f66677-9bd2-4fa4-9248-a14c57aec4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde6780-63f0-45d7-a859-085fab5c5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= pd.Categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d67852-a005-453f-97ce-ef8221a778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21ca2c-cd4b-4ec9-9458-c533b659600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns= ['age_of_child', 'child_sex', 'birth_order', 'current_breast_feeding', 'birth_weight', 'birth_interval', 'womens_age', 'Place_of_residence', 'mother_edu_stat', 'marital_stats', 'no_of_under_five_child', 'media_exposure', 'sex_of_hh_head', 'household_size', 'household_wealth_stat', 'water_source', 'ANc_visit', 'place_of_delivery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930db655-78b6-4aa3-895f-257f265caa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_columns:\n",
    "    X[i]= pd.Categorical(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffadf21-8c8d-43b7-b2a0-b9b19a511d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.get_dummies(X,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d653366-f22e-48df-be10-bae1a68aa6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1.shape ,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fd2d3-d4d9-4053-804c-e567619ed2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.Series(y, name= 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630c2b9-32ff-4509-a73d-6ecb7d4d970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([data1 ,Y],axis=1) #concatenate onehot encoded dataframe with outcome variable and named the result as data4\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b59ae-1497-4ef5-8905-fbda37a24cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf6257-36cd-484c-aae3-ff6581121cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0980a-1f50-4de1-bcbb-0838b9d48865",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy1 = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8dc81-555c-48dc-978f-d8904308b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape,data2.shape ,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc97d9-81b9-4b82-8592-7ed9d33751f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5e446-aa39-4871-afc3-13d32179e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert boolean values to integers for both X and Y\n",
    "X1 = data2.drop('target', axis=1).astype(np.int64)\n",
    "Y1 = data2['target'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3f82b-c597-4d64-972f-fc0645704a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381247bd-92dd-4d1f-a2cd-9f1f432cf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d170418-7227-4c43-aa5a-3611a2a27c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X1,Y1, test_size=0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb57eee-5840-4760-a7ff-15384688a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff6740-4261-4149-8d13-3e755574544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified', random_state=0)\n",
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e74ed-d035-4507-b496-882171658538",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aece13b-4f23-4273-b88d-6005698a87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don't want to see warnings for now\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7eef17-d0f8-4061-8ca3-72c5d34abbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473490af-1869-4c6b-8606-7a1560f317e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Random_Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'MLP classifier' : MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872b8a8-2b88-42ac-9c3c-971a8d9f2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, precision_score, recall_score, f1_score, confusion_matrix,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = plt.cm.get_cmap('tab10', len(models))\n",
    "\n",
    "# Evaluate each classifier\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    # Training accuracy\n",
    "    y_train_pred = model.predict(x_train)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    training_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Training accuracy: {training_accuracy:.2f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"roc_auc: {roc_auc:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c951ef-1df1-4a7a-86a9-f6ac159eae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\x_train.pkl','wb') as file:\n",
    "    pickle.dump(x_train,file)\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\y_train.pkl','wb') as file:\n",
    "    pickle.dump(y_train,file)\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\x_test.pkl','wb') as file:\n",
    "    pickle.dump(x_test,file)\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\x_test.pkl','wb') as file:\n",
    "    pickle.dump(y_test,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe912ae-bf2c-426f-ad47-661a522f5d9c",
   "metadata": {},
   "source": [
    "## summarize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e7601-6b5e-4936-bd9b-4a8abdac7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0de28a-409d-4d78-9cf2-fd1c861aeb82",
   "metadata": {},
   "source": [
    "## Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080ae82-eff5-4195-9ae9-15b8838ed8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X1, Y1)\n",
    "\n",
    "# Convert resampled data to DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=data2.columns[:-1])\n",
    "df_resampled['target'] = y_resampled\n",
    "\n",
    "# Count class distribution after SMOTE\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(df_resampled['target'].value_counts())\n",
    "\n",
    "# Visualize class distribution before and after SMOTE\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=data2, x='target')\n",
    "plt.title(' Before SMOTE')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(data=df_resampled, x='target')\n",
    "plt.title(' After SMOTE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de991450-181b-4c08-8cd7-38e9d4127489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b228100-d433-4bcf-a339-1f1a91ca4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_resampled, y_resampled , test_size=0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8128ee5-9396-49fd-96f2-4a32a98ba84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_auc_score\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = plt.cm.get_cmap('tab10', len(models))\n",
    "\n",
    "# Evaluate each classifier\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Training accuracy\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    training_accuracy = accuracy_score(Y_train, y_train_pred)\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    \n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Training accuracy: {training_accuracy:.2f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"roc_auc: {roc_auc:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca84683-834f-4996-865e-ba41a8c54d13",
   "metadata": {},
   "source": [
    "## roc curve "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39ebd2-69c6-4da6-a7aa-48ea8a99ac98",
   "metadata": {},
   "source": [
    "## F1 score and precison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a56c49-590a-4d9e-978b-ee54717ef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "# Initialize the figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate through the models and plot the metrics\n",
    "model_num = 1\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"{name} (Model {model_num})\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada9d71-16b5-42ae-a8ae-2e1fa8faa47d",
   "metadata": {},
   "source": [
    "##Sub group analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b564efa-7d75-47fb-9e96-b4eba57376f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c96209-3caf-48c0-8266-243813248fc7",
   "metadata": {},
   "source": [
    "## subgroup analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb92b70-c792-4e8c-8753-6ef6430ebda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your subgroups\n",
    "subgroup_vars = ['place_of_residence', 'sex_of_hh_head', 'water_source', \n",
    "                 'number_of_underfive_children', 'place_of_delivery']\n",
    "\n",
    "# Initialize result storage\n",
    "subgroup_results = []\n",
    "\n",
    "for var in subgroup_vars:\n",
    "    for value in new_df[var].unique():\n",
    "        subgroup_name = f\"{var} = {value}\"\n",
    "        \n",
    "        # Filter rows for this subgroup\n",
    "        idx = df[var] == value\n",
    "        y_true_sub = y_true[idx]\n",
    "        y_pred_sub = y_pred[idx]\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_true_sub, y_pred_sub)\n",
    "        precision = precision_score(y_true_sub, y_pred_sub)\n",
    "        recall = recall_score(y_true_sub, y_pred_sub)\n",
    "        f1 = f1_score(y_true_sub, y_pred_sub)\n",
    "\n",
    "        # Store results\n",
    "        subgroup_results.append({\n",
    "            \"Subgroup\": subgroup_name,\n",
    "            \"Accuracy\": round(accuracy * 100, 2),\n",
    "            \"Precision\": round(precision * 100, 2),\n",
    "            \"Recall\": round(recall * 100, 2),\n",
    "            \"F1 Score\": round(f1 * 100, 2)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(subgroup_results)\n",
    "results_df.sort_values(\"Subgroup\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf9d6b-6040-4ef5-b847-5cfa8c87892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Initialize the figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate through the models and plot the ROC curves\n",
    "model_num = 1\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get the probability of the positive class\n",
    "    fpr, tpr, _ = roc_curve(Y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'{name} (Model {model_num}) (AUC = {roc_auc:.2f})')\n",
    "    model_num += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot the diagonal line (random classifier)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b9a31-3396-4aed-aacf-a587134fdddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9e2a4-c317-4215-be96-da1a89faddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('roc_curve111.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae0eda-e5e3-4c75-8bbe-8f626cb503b5",
   "metadata": {},
   "source": [
    "## Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771605f-fd23-4501-a2f1-10d926d74b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Random_Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'MLP classifier': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store confusion matrices\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Train models and compute confusion matrices\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_test, y_pred).ravel()\n",
    "    \n",
    "    # Store the confusion matrix\n",
    "    confusion_matrices[model_name] = {\n",
    "        'True Negative (TN)': tn,\n",
    "        'False Positive (FP)': fp,\n",
    "        'False Negative (FN)': fn,\n",
    "        'True Positive (TP)': tp\n",
    "    }\n",
    "\n",
    "# Print the confusion matrices for each model\n",
    "for model_name, cm in confusion_matrices.items():\n",
    "    print(f\"Confusion Matrix for {model_name}:\")\n",
    "    print(cm)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91832aff-eb51-4bbf-800b-86208072f0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db096946-b106-4789-850e-2a40043d95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\X_train.pkl','wb') as file:\n",
    "    pickle.dump(X_train,file)\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\Y_train.pkl','wb') as file:\n",
    "    pickle.dump(Y_train,file)\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\X_test.pkl','wb') as file:\n",
    "    pickle.dump(X_test,file)\n",
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\Y_test.pkl','wb') as file:\n",
    "    pickle.dump(Y_test,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f651-54e8-43a2-ba6b-090aa1144f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pickle.load(open('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\X_train.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6b286-55fa-4762-b6c1-bb7298a15c4c",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2e136-f7f7-4b0c-986a-68d958e16a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "list_trees = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250]\n",
    "def objective(trial):\n",
    "   rf_n_estimators = trial.suggest_categorical('rf_n_estimators', list_trees)\n",
    "   rf_max_features = trial.suggest_uniform('rf_max_features', 0.15, 1.0)\n",
    "   rf_min_samples_split = trial.suggest_int('rf_min_samples_split', 2, 14)\n",
    "   rf_min_samples_leaf = trial.suggest_int('rf_min_samples_leaf', 1, 14)\n",
    "   rf_max_samples = trial.suggest_uniform('rf_max_samples', 0.6, 0.99)\n",
    "\n",
    "   rf_clfOpt = RandomForestClassifier(n_estimators=rf_n_estimators,\n",
    "                             max_features=rf_max_features, min_samples_split=rf_min_samples_split,\n",
    "                             min_samples_leaf=rf_min_samples_leaf, max_samples=rf_max_samples,\n",
    "                             bootstrap=True, n_jobs=-1, verbose=0)\n",
    "   return cross_val_score(rf_clfOpt,X_train, Y_train, cv=cv).mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a5d78-100a-4c57-baa7-c66369e7ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a3877-d56c-4a9d-8383-e99c10f4e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best trial:\n",
    "print(f\"The best trial is : \\n{study.best_trial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed86b6d-fd4a-4cce-a850-99532e71d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best score:\n",
    "print(f\"The best accuracy value is : \\n{study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220b714-560f-4ca6-a4e8-807934a06c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35734475-4cb5-495e-8375-e03f70fc1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimized = RandomForestClassifier(n_estimators= 125,\n",
    "                                      max_features =  0.846130971306992,\n",
    "                                      min_samples_split = 4,\n",
    "                                      min_samples_leaf = 1,\n",
    "                                      max_samples = 0.9882448042440699)\n",
    "\n",
    "\n",
    "\n",
    "cross_val_score(rf_optimized,X_train, Y_train, cv=cv, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f56a64-0577-4669-b9b4-b812d94fc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf_optimized,X_test, Y_test, cv=cv, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bcf0d-5ff8-48a7-881c-2281fca3956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf_optimized,X_train, Y_train, cv=cv, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422bf06-ab90-4661-805e-0382ac28934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf_optimized,X_test, Y_test, cv=cv, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354bcba-afa2-4b50-bce0-a7d3018d0802",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12411740-7009-4d43-af9c-9b00976ef6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimized = RandomForestClassifier(n_estimators=125,\n",
    "                                     max_features=0.846130971306992,\n",
    "                                     min_samples_split=4,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     max_samples=0.9882448042440699)\n",
    "\n",
    "rf_optimized.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "mdi_importances = pd.Series(\n",
    "    rf_optimized.feature_importances_, index=feature_names\n",
    ").sort_values(ascending=True)\n",
    "\n",
    "mdi_importances = mdi_importances.sort_values(ascending=False)\n",
    "mdi_importances = mdi_importances.nlargest(10)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "mdi_importances.plot.barh()\n",
    "plt.title(\"Random Forest Feature Importances \")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd9388-2945-4a9c-b406-ab3e5b41ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('C:\\\\Users\\\\HP\\\\Desktop\\\\new_ana\\\\pickled\\\\rf_optimized.pkl','wb') as file:\n",
    "    pickle.dump(rf_optimized,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c31963-7766-4775-816f-4db689f25835",
   "metadata": {},
   "source": [
    "## prediction using optimized best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b8754-1072-44ae-a889-112fd3dfb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "rf_optimized.fit(X_train, Y_train) # this is model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09930ff0-5767-440f-be40-7c5d1d215ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredicted2 = rf_optimized.predict(X_test) #prediction of the test data based on the trainng/learning\n",
    "confusion_matrix(Y_test, ypredicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd762c-71c2-4776-983b-7544a2708d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_optimized.fit(X_train, Y_train) # this is model training\n",
    "ypredicted2 = rf_optimized.predict(X_test)\n",
    "explainer = shap.Explainer(rf_optimized, X_train)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089bbad-dd0d-4cc0-b78a-a28b9ced384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/slundberg/shap/issues/1460\n",
    "import numpy as np\n",
    "class_names = [\"adequate\", \"inadequate\"]\n",
    "shapObject = shap_values\n",
    "shap.summary_plot(\n",
    "    shap_values=np.take(shapObject.values, 0, axis=-1),\n",
    "    features=X_train,\n",
    "    plot_type=\"bar\",\n",
    "    max_display=10,\n",
    "    title=\"SHAP from optimized Random Forest model\",\n",
    "    class_names=[\"Class 0\", \"Class 1\"]  # Replace with the actual class names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65b4e9-8218-4ff7-abf6-710078df9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('shap.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44d596-d9a1-4357-89f5-377c72c1a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapObject = shap_values\n",
    "shap.summary_plot(shap_values = np.take(shapObject.values,0,axis=-1),\n",
    "                  features = X_test,\n",
    "                  max_display=10,\n",
    "                  title = \"SHAP beeswarm plot based on Random Forest model\")\n",
    "#               show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d985c4-2b8b-410a-aa21-2158a251f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap import Explainer, Explanation\n",
    "from shap import waterfall_plot\n",
    "\n",
    "#local explanation for positivnegative class\n",
    "exp = Explanation(shap_values[:,:,0], shap_values.base_values[:,0], X_train, feature_names=X_train.columns)\n",
    "idx = 7 # datapoint to explain\n",
    "waterfall_plot(exp[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c341a68-5732-4e1e-9a3c-41befd4ff52d",
   "metadata": {},
   "source": [
    "## second class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf6e97-8925-4b0c-99c8-85dd263662b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall_plot(exp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55455e-07e9-4446-9312-98cbdc88c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(Y_test, ypredicted2)\n",
    "\n",
    "# True positives (TP), false positives (FP), true negatives (TN), false negatives (FN)\n",
    "# can be extracted from the confusion matrix\n",
    "\n",
    "# Assuming the positive class is the minority class (adjust based on your problem)\n",
    "TP = cm[1, 1]  # True positives (referring to the row and column for the positive class)\n",
    "FP = cm[0, 1]  # False positives\n",
    "TN = cm[0, 0]  # True negatives\n",
    "FN = cm[1, 0]  # False negatives\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "# Print the results\n",
    "print(\"Sensitivity (Recall):\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2b450-fdc3-4056-aa7e-1b700b3e56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf_optimized, X_test, Y_test, n_repeats=10, random_state=123, n_jobs=2)\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X_test.columns[sorted_importances_idx],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6165984-1319-4fb9-aeb6-caa28b6040be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_unbalanced = RandomForestClassifier(random_state=123)\n",
    "rfc_unbalanced.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb95247-919e-4603-ab84-96ef25dc4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_balanced = RandomForestClassifier(random_state=123)\n",
    "rfc_balanced.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ade0e0-aaf9-41a3-affe-e85257849481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc optimized with optuna\n",
    "rf_optimized = rf_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a29fbf-db91-4d6c-b805-919269782d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# ... your code for importing data (xtest, ytest, etc.) and building models (rfc_unbalanced, etc.)\n",
    "\n",
    "# Create separate RocCurveDisplay objects for each model\n",
    "rfc_unbalanced_disp = RocCurveDisplay.from_estimator(rfc_unbalanced, X=x_test, y=y_test,\n",
    "                                                    name='RF on Unbalanced Data')\n",
    "rfc_balanced_disp = RocCurveDisplay.from_estimator(rfc_balanced, X=X_test, y=Y_test,\n",
    "                                                    name='RF on Balanced Data',\n",
    "                                                    ax=rfc_unbalanced_disp.ax_)\n",
    "rfc_optimized_disp = RocCurveDisplay.from_estimator(rf_optimized, X=X_test, y=Y_test,\n",
    "                                                    name='RF after Optimization',\n",
    "                                                    ax=rfc_unbalanced_disp.ax_,\n",
    "                                                    color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0961e6-bb7b-4f8f-abe3-65730921560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model with ROC and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#Predict probabilities for the test set\n",
    "y_prob = rfc_balanced.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC): Random forest balanced')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Value: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b57f17-3202-4a62-a266-6ce992f321b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model with ROC and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#Predict probabilities for the test set\n",
    "y_prob = rfc_unbalanced.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC): Random forest unbalanced')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Value: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384d994-9996-40a9-8335-778794d1d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model with ROC and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#Predict probabilities for the test set\n",
    "y_prob =rf_optimized.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC): Random forest optimized')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Value: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496bb00-7601-41b4-bc7f-e7bf52e15a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimized = RandomForestClassifier(random_state=123)\n",
    "rf_optimized.fit(X_train, Y_train)\n",
    "y_pred = rf_optimized.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "# Get individual values from confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Create heatmap with annotations inside cells\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=['inadequate', 'adequate'], yticklabels=['inadequate', 'adequate'])\n",
    "\n",
    "# Adjust cell text positioning slightly for better alignment\n",
    "plt.text(0.52, 0.48, f'{tp}', ha='center', va='center', fontsize=12, bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "plt.text(1.52, 0.48, f'{fp}', ha='center', va='center', fontsize=12, bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "plt.text(0.52, 1.48, f'{fn}', ha='center', va='center', fontsize=12, bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "plt.text(1.52, 1.48, f'{tn}', ha='center', va='center', fontsize=12, bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix from optimized random forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a49e3d-d10e-424c-a6fb-20eb50e5d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimized = RandomForestClassifier(random_state=123)\n",
    "rf_optimized.fit(X_train, Y_train)\n",
    "y_pred = rf_optimized.predict(X_test)\n",
    "f1 = f1_score(Y_test, y_pred)\n",
    "recall = recall_score(Y_test, y_pred)\n",
    "precision = precision_score(Y_test, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabb703-eae2-4c24-82f2-b35c400dd7cd",
   "metadata": {},
   "source": [
    "## Rule mining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007f6fe-55c3-4b18-9b36-1e2bed3e165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "# Ensure arrays are writable\n",
    "X_train =X_train.copy()\n",
    "Y_train  = Y_train.copy()\n",
    "data2 = data2.copy()\n",
    "rf_optimized = RandomForestClassifier(n_estimators= 125,\n",
    "                                      max_features =  0.846130971306992,\n",
    "                                      min_samples_split = 4,\n",
    "                                      min_samples_leaf = 1,\n",
    "                                      max_samples = 0.9882448042440699)\n",
    "rf_optimized.fit(X_train, Y_train)\n",
    "# Get the feature importances\n",
    "feature_importances = rf_optimized.feature_importances_\n",
    "\n",
    "# Select the top k features based on feature importance\n",
    "k = 10  # Number of top features to select\n",
    "top_features = X_train.columns[feature_importances.argsort()[-k:]].tolist()\n",
    "\n",
    "# Create a new DataFrame with only the top features\n",
    "top_df = data2[top_features + ['target']]  # Ensure 'fd' is the correct target column in data4\n",
    "\n",
    "# Convert the DataFrame to a list of transactions\n",
    "transactions = []\n",
    "for i in range(len(top_df)):\n",
    "    transaction = [f\"{top_df.columns[j]}={str(top_df.values[i, j])}\" for j in range(len(top_features))]\n",
    "    transactions.append(transaction)\n",
    "\n",
    "# Print a sample of the transactions to verify correctness\n",
    "print(\"Sample transactions:\")\n",
    "for t in transactions[:5]:\n",
    "    print(t)\n",
    "\n",
    "# Run the Apriori algorithm with further reduced thresholds\n",
    "rules = list(apriori(transactions, min_support=0.001, min_confidence=0.01, min_lift=1.1, max_length=3))\n",
    "\n",
    "# Print the number of rules generated\n",
    "print(f\"Number of rules generated: {len(rules)}\")\n",
    "\n",
    "# Print the results\n",
    "if not rules:\n",
    "    print(\"No rules generated.\")\n",
    "else:\n",
    "    for rule in rules:\n",
    "        for ordered_stat in rule.ordered_statistics:\n",
    "            items_base = list(ordered_stat.items_base)\n",
    "            items_add = list(ordered_stat.items_add)\n",
    "            support = rule.support\n",
    "            confidence = ordered_stat.confidence\n",
    "            lift = ordered_stat.lift\n",
    "            if items_base and items_add:  # Ensure there are items in both base and add\n",
    "                print(f\"Rule: {', '.join(items_base)} -> {', '.join(items_add)} (support={support:.3f}, confidence={confidence:.3f}, lift={lift:.3f})\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc729159-4832-4fef-abea-248cb68e435c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
